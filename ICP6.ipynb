{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text processing\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from gensim import corpora, models, similarities\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the csv file with amazon reviews\n",
    "reviews_df=pd.read_csv('C:\\\\Users\\\\Ansh\\\\test\\\\icp6\\\\abcnews.csv',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_date      int64\n",
      "headline_text    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(reviews_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['headline_text'] = reviews_df['headline_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   publish_date                                      headline_text\n",
      "0      20030219  aba decides against community broadcasting lic...\n",
      "1      20030219     act fire witnesses must be aware of defamation\n",
      "2      20030219     a g calls for infrastructure protection summit\n",
      "3      20030219           air nz staff in aust strike for pay rise\n",
      "4      20030219      air nz strike to affect australian travellers\n",
      "5      20030219                  ambitious olsson wins triple jump\n"
     ]
    }
   ],
   "source": [
    "print(reviews_df.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_clean(text):\n",
    "    \"\"\"\n",
    "    Function to clean text-remove punctuations, lowercase text etc.\n",
    "    \"\"\"\n",
    "    text = re.sub(\"[^a-zA-Z ]\", \"\", text)\n",
    "    text = text.lower()  # lower case text\n",
    "    text = nltk.word_tokenize(text)\n",
    "    return (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['news', 'say','use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do','took','time','year',\n",
    "'done', 'try', 'many', 'some','nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line','even', 'also', 'may', 'take', 'come', 'new','said', 'like','people'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "     return [word for word in text if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(text):\n",
    "    \"\"\"\n",
    "    Function to stem words\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = [stemmer.stem(word) for word in text]\n",
    "        text = [word for word in text if len(word) > 1] # no single letter words\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_all(text):\n",
    "    \"\"\"\n",
    "    This function applies all the functions above into one\n",
    "    \"\"\"\n",
    "    return stem_words(remove_stop_words(initial_clean(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean reviews and create new column \"tokenized\"\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean and tokenize 118253 reviews: 0.4888541539510091 min\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "reviews_df['tokenized_reviews'] = reviews_df['headline_text'].apply(apply_all)\n",
    "t2 = time.time()\n",
    "print(\"Time to clean and tokenize\", len(reviews_df), \"reviews:\", (t2-t1)/60, \"min\") #Time to clean and tokenize 3209 reviews: 0.21254388093948365 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews with their respective tokenize version:\n",
      "   publish_date                                      headline_text  \\\n",
      "0      20030219  aba decides against community broadcasting lic...   \n",
      "1      20030219     act fire witnesses must be aware of defamation   \n",
      "2      20030219     a g calls for infrastructure protection summit   \n",
      "3      20030219           air nz staff in aust strike for pay rise   \n",
      "4      20030219      air nz strike to affect australian travellers   \n",
      "\n",
      "                               tokenized_reviews  \n",
      "0        [aba, decid, commun, broadcast, licenc]  \n",
      "1            [act, fire, wit, must, awar, defam]  \n",
      "2         [call, infrastructur, protect, summit]  \n",
      "3      [air, nz, staff, aust, strike, pay, rise]  \n",
      "4  [air, nz, strike, affect, australian, travel]  \n"
     ]
    }
   ],
   "source": [
    "print(\"reviews with their respective tokenize version:\" )\n",
    "print(reviews_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "import gensim\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gensim dictionary from the tokenized data\n",
    "tokenized = reviews_df['tokenized_reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating term dictionary of corpus, where each unique term is assigned an index.\n",
    "dictionary = corpora.Dictionary(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter terms which occurs in less than 1 review and more than 80% of the reviews.\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]]\n"
     ]
    }
   ],
   "source": [
    "#convert the dictionary to a bag of words corpus\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in tokenized]\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('aba', 1), ('broadcast', 1), ('commun', 1), ('decid', 1), ('licenc', 1)]]\n"
     ]
    }
   ],
   "source": [
    "print([[(dictionary[id], freq) for id, freq in cp] for cp in corpus[:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create model in  118253 reviews: 10.44262334505717 min\n"
     ]
    }
   ],
   "source": [
    "#LDA\n",
    "t3 = time.time()\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 5, id2word=dictionary, passes=15)\n",
    "t4 = time.time()\n",
    "print(\"create model in \", len(reviews_df), \"reviews:\", (t4-t3)/60, \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "ldamodel.save('model_combined.gensim')\n",
    "topics = ldamodel.print_topics(num_words=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now printing the topics and their composition\n",
      "This output shows the Topic-Words matrix for the 7 topics created and the 4 words within each topic\n",
      "(0, '0.022*\"council\" + 0.020*\"govt\" + 0.014*\"labor\" + 0.013*\"plan\" + 0.007*\"qld\" + 0.007*\"water\" + 0.007*\"elect\" + 0.006*\"fund\"')\n",
      "(1, '0.035*\"polic\" + 0.020*\"man\" + 0.018*\"charg\" + 0.014*\"court\" + 0.013*\"face\" + 0.010*\"death\" + 0.010*\"murder\" + 0.009*\"drug\"')\n",
      "(2, '0.015*\"call\" + 0.013*\"plan\" + 0.010*\"urg\" + 0.009*\"boost\" + 0.009*\"group\" + 0.009*\"govt\" + 0.009*\"fund\" + 0.009*\"health\"')\n",
      "(3, '0.018*\"win\" + 0.012*\"servic\" + 0.011*\"gold\" + 0.009*\"home\" + 0.008*\"alp\" + 0.008*\"oil\" + 0.008*\"final\" + 0.007*\"centr\"')\n",
      "(4, '0.029*\"us\" + 0.017*\"iraq\" + 0.012*\"kill\" + 0.010*\"australia\" + 0.008*\"two\" + 0.008*\"australian\" + 0.008*\"market\" + 0.007*\"iraqi\"')\n"
     ]
    }
   ],
   "source": [
    "print(\"Now printing the topics and their composition\")\n",
    "print(\"This output shows the Topic-Words matrix for the 7 topics created and the 4 words within each topic\")\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first review is:\n",
      "aba decides against community broadcasting licence\n",
      "\n",
      "\n",
      "The similarity of this review with the topics and respective similarity score are \n",
      "[(0, 0.19991545), (1, 0.03334793), (2, 0.7000407), (3, 0.033347953), (4, 0.033347946)]\n"
     ]
    }
   ],
   "source": [
    "#finding the similarity of the first review with topics\n",
    "print(\"first review is:\")\n",
    "print(reviews_df.headline_text[0])\n",
    "get_document_topics = ldamodel.get_document_topics(corpus[0])\n",
    "print('\\n')\n",
    "print(\"The similarity of this review with the topics and respective similarity score are \")\n",
    "print(get_document_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, pyLDAvis.show() is not the best command\n",
      "      to use. Consider using pyLDAvis.display(), or pyLDAvis.enable_notebook().\n",
      "      See more information at http://pyLDAvis.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8889/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [08/Mar/2020 18:45:24] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2020 18:45:24] \"GET /LDAvis.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2020 18:45:24] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2020 18:45:24] \"GET /LDAvis.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "#visualizing topics\n",
    "lda_viz = gensim.models.ldamodel.LdaModel.load('model_combined.gensim')\n",
    "lda_display = pyLDAvis.gensim.prepare(lda_viz, corpus, dictionary, sort_topics=True)\n",
    "pyLDAvis.show(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
